{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script fetches all of the relevant data from the EO Run 7 test plan and formats it for insertion to the confluence database\n",
    "### Requirements\n",
    "- The [`ts_planning_tool`](https://github.com/lsst-ts/ts_planning_tool/tree/develop) package, which allows you to use the Zephyr Scale API\n",
    "- A text file named `credentials.txt` that contains the following three lines at the top of the file:\n",
    "    - ZEPHYR_TOKEN: A token for the Zephyr Scale API\n",
    "    - JIRA_API_TOKEN: A token for the JIRA api\n",
    "    - JIRA_USERNAME: Your jira username, which is usually your email (ex. seanmacb@umich.edu)\n",
    "- Due to sub-shells, you also have to define these environment variables directly within the `cli.py` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:18:57.888661Z",
     "iopub.status.busy": "2024-09-19T15:18:57.888355Z",
     "iopub.status.idle": "2024-09-19T15:18:58.391524Z",
     "shell.execute_reply": "2024-09-19T15:18:58.391198Z",
     "shell.execute_reply.started": "2024-09-19T15:18:57.888638Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/Users/sean/Desktop/Repos/ts_planning_tool/\")\n",
    "sys.path.append(\"/Users/sean/Desktop/Repos/ts_planning_tool/python/lsst/ts/planning/tool/\")\n",
    "import cli as zcli\n",
    "import zephyr_interface as zint\n",
    "import tests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import warnings\n",
    "# Settings the warnings to be ignored - this is prevalent with the numpydatetime64 object\n",
    "warnings.filterwarnings('ignore') \n",
    "base_web_link = \"https://s3df.slac.stanford.edu/data/rubin/lsstcam\"\n",
    "base_weekly = \"w_2024_35\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:05:11.851744Z",
     "iopub.status.busy": "2024-09-19T15:05:11.851562Z",
     "iopub.status.idle": "2024-09-19T15:05:11.853673Z",
     "shell.execute_reply": "2024-09-19T15:05:11.853443Z",
     "shell.execute_reply.started": "2024-09-19T15:05:11.851733Z"
    }
   },
   "source": [
    "#### Setting appropriate environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:18:58.392287Z",
     "iopub.status.busy": "2024-09-19T15:18:58.392123Z",
     "iopub.status.idle": "2024-09-19T15:18:58.394785Z",
     "shell.execute_reply": "2024-09-19T15:18:58.394512Z",
     "shell.execute_reply.started": "2024-09-19T15:18:58.392276Z"
    }
   },
   "outputs": [],
   "source": [
    "export_vars = [\"ZEPHYR_TOKEN\",\"JIRA_API_TOKEN\",\"JIRA_USERNAME\"]\n",
    "\n",
    "with open('credentials.txt','r') as f:\n",
    "    for variables in export_vars:\n",
    "        line = f.readline()[:-1]\n",
    "        os.environ[variables] = line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting headers for an HTTP authentication\n",
    "- These headers are used for querying the usernames of whoever executed the test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:18:58.395458Z",
     "iopub.status.busy": "2024-09-19T15:18:58.395315Z",
     "iopub.status.idle": "2024-09-19T15:18:58.397551Z",
     "shell.execute_reply": "2024-09-19T15:18:58.397251Z",
     "shell.execute_reply.started": "2024-09-19T15:18:58.395448Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {'Content-Type': 'application/json','Accept': 'application/json'}\n",
    "auth = HTTPBasicAuth(\"seanmacb@umich.edu\", os.environ[\"JIRA_API_TOKEN\"])\n",
    "zepint = zint.ZephyrInterface(jira_api_token=os.environ[\"JIRA_API_TOKEN\"],jira_username=os.environ[\"JIRA_USERNAME\"])\n",
    "zepint.zephyr_api_token = os.environ[\"ZEPHYR_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming all of the relevant test cases\n",
    "- Our test cases for Run 7 were `BLOCK-R66 - BLOCK-R78` and `BLOCK-R95`. If there are other test cases you would like to add for querying, this block is where you should do that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:18:58.398890Z",
     "iopub.status.busy": "2024-09-19T15:18:58.398756Z",
     "iopub.status.idle": "2024-09-19T15:18:58.400851Z",
     "shell.execute_reply": "2024-09-19T15:18:58.400601Z",
     "shell.execute_reply.started": "2024-09-19T15:18:58.398878Z"
    }
   },
   "outputs": [],
   "source": [
    "test_cases_arr = []\n",
    "for k in range(13):\n",
    "    test_cases_arr.append(\"BLOCK-R{}\".format(66+k))\n",
    "test_cases_arr.append(\"BLOCK-R95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A helper function to format database entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:18:58.401594Z",
     "iopub.status.busy": "2024-09-19T15:18:58.401360Z",
     "iopub.status.idle": "2024-09-19T15:18:58.405764Z",
     "shell.execute_reply": "2024-09-19T15:18:58.405320Z",
     "shell.execute_reply.started": "2024-09-19T15:18:58.401578Z"
    }
   },
   "outputs": [],
   "source": [
    "def formatter(execu):\n",
    "    e_num = execu['key'][6:]\n",
    "    date = np.datetime64(execu['actualEndDate'])\n",
    "    # splitTime = date.split(\"T\")\n",
    "    # base_str = \"\"\n",
    "    # for entry in splitTime:\n",
    "    #     base_str += entry+\" \"\n",
    "    # base_str = base_str[:-1]\n",
    "    # date = np.datetime64(base_str)\n",
    "    # shifter = zepint.get_user_name(execu[\"execuutedById\"]) # Not yet implemented, working on it\n",
    "    step_config_parse = zepint.parse(execu[\"testCase\"])\n",
    "\n",
    "    name_url = zepint.jira_base_url+\"user?accountId=\"+execu[\"executedById\"]\n",
    "    name_response = requests.get(name_url,headers=headers,auth=auth)\n",
    "    shifter = name_response.json()[\"displayName\"]\n",
    "    \n",
    "    step_config = (step_config_parse)\n",
    "    E2V_seq = execu[\"customFields\"][\"E2V sequencer config\"]\n",
    "    ITL_seq = execu[\"customFields\"][\"ITL sequencer config\"]\n",
    "    Corner_seq = execu[\"customFields\"][\"Corner sequencer config\"]\n",
    "    CCS_distrib = execu[\"customFields\"][\"CCS Distribution\"] # Not yet implemented\n",
    "    comments = execu[\"comment\"]\n",
    "    hv = execu[\"customFields\"][\"HV on?\"]\n",
    "    status = (zepint.parse(execu[\"testExecutionStatus\"]))\n",
    "    weekly_dist = base_weekly if execu[\"customFields\"][\"Pipeline weekly distribution\"]==None else execu[\"customFields\"][\"Pipeline weekly distribution\"]\n",
    "\n",
    "    if type(comments)!=type(None):\n",
    "        comments = comments.replace(\"<br>\",\", \")\n",
    "    \n",
    "    return {\"Run #\":e_num,\"Date\":date,\"Shifter\":shifter,\n",
    "            \"step/config\":step_config,\"E2V Sequencer file\":E2V_seq,\n",
    "            \"ITL Sequencer File\":ITL_seq,\"Corner Sequencer File\":Corner_seq,\n",
    "            \"CCS Distribution\":CCS_distrib,\"HV on?\":hv,\"Zephyr Comments\":comments,\"Status\":status,\n",
    "            \"Web report\":\"{}/{}/{}/\".format(base_web_link,e_num,weekly_dist),\"User comments\":\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A cutoff date to only query data from after a certain date\n",
    "- If you would like to query all data, enter `2024-07-01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:18:58.406551Z",
     "iopub.status.busy": "2024-09-19T15:18:58.406397Z",
     "iopub.status.idle": "2024-09-19T15:18:58.408643Z",
     "shell.execute_reply": "2024-09-19T15:18:58.408241Z",
     "shell.execute_reply.started": "2024-09-19T15:18:58.406539Z"
    }
   },
   "outputs": [],
   "source": [
    "cutoff_date = np.datetime64(\"2024-09-14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The kernel that queries the data, formats it into a dataframe, and writes the dataframe to a file named `ZephyrRecords.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T15:18:58.409251Z",
     "iopub.status.busy": "2024-09-19T15:18:58.409152Z",
     "iopub.status.idle": "2024-09-19T15:21:12.362100Z",
     "shell.execute_reply": "2024-09-19T15:21:12.361349Z",
     "shell.execute_reply.started": "2024-09-19T15:18:58.409239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished, .csv contains 7 entries\n"
     ]
    }
   ],
   "source": [
    "first = False\n",
    "for block in test_cases_arr:\n",
    "    a = await zepint.list_test_executions(block,max_results=10000)\n",
    "    if len(a['values'])!=0:\n",
    "        for execution in a['values']:\n",
    "            if (await (zepint.parse(execution[\"testExecutionStatus\"])))['name'] != \"Not Executed\" and np.datetime64(execution['actualEndDate'].split(\"T\")[0])>cutoff_date:\n",
    "                result = formatter(execution)\n",
    "                result[\"Status\"] = (await result[\"Status\"])['name']\n",
    "                # result[\"Shifter\"] = await result[\"Shifter\"]\n",
    "                result[\"step/config\"] = (await result[\"step/config\"])[\"name\"].split(\" \")[-1] \n",
    "                if not first:\n",
    "                    myDF = pd.DataFrame(columns=list(result.keys()))\n",
    "                    first=True\n",
    "                myDF.loc[len(myDF.index)] =list(result.values())\n",
    "myDF.sort_values(\"Date\",ascending=False).to_csv(\"{}/ZephyrRecords.csv\".format(os.getcwd()),header=True,index=False)\n",
    "print(\"Finished, .csv contains {} entries\".format(len(myDF)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
